# Cycle-GAN / UDCT
Modified version of the UDCT cycle-GAN. Different data processing and complete validation added.
Version uses Tensorflow(-GPU) 1.4 and Python 2.7. Python 2.7 was chosen for the original implementation.
Therefore, to avoid bugs, we chose the same version. 
Tests with python 3.6 and TF-GPU 1.5 were also done and the code seemed to work (in depth-testing still required)
Other requirements are provided in the file requirements.txt.

## Installation
1.  Clone or download the repository:
    <pre> git clone https://github.com/Demisio/UDCT.git </pre>
2.  Create an environment for the packages to be installed. With conda, e.g (less tested with python 3.6 & TF 1.5 but seems to work): 
    <pre >conda create -n UDCT python=2.7 
    conda create -n UDCT python=3.6</pre>

2.  Install requirements via: 
    <pre> pip install -r requirements.txt </pre>
4.  Required CUDA / CUDNN versions:
    <pre>Python 2.7, TF 1.4: CUDA 8.0 / CUDNN 6.0
    Python 3.6, TF 1.5: CUDA 9.0 / CUDNN 7.0</pre>
    
## Creating a Dataset, Data Splits and Log Folders
1.  Images are given in ./Data/Heart/3D. Creating a hdf5 dataset is achieved by navigating into the folder dataprocessing
    and executing the file heart_augment_loader.py 
    
    (make sure that variable syn_data_path inside the script is set to: './../Data/Heart/3D/Segmented_noisy/')
    <pre>cd data_processing
    python heart_augment_loader.py</pre>
2.  Datasplits are already provided but can be generated by navigating into the folder ./train_test_split and executing
    the file create_splits.py
    <pre>cd train_test_split
    python create_splits.py</pre>
3.  2 Dictionaries, called "logs" and "Models" have to be created in the main Project folder. These dictionaries should
    contain subfolders with the name of the experiment and 5 subsubfolders called fold_1 until fold_5, e.g.:
    <pre>./Models/Heart_full/fold_1
    ./logs/Heart_full/fold_4</pre>
   
   
## Creating a Dataset with Limited Data
1.  Navigate into the folder 'data_processing' and execute:
    <pre>data_processing/heart_lim_dat_from_full_dat.py</pre>
    This creates new volumes with the same size as the others but containing limited and duplicated data.
    
    The variable data_path and save_path inside the script define which data should be used and where it should be saved respectively.
    values could be as shown below (make sure folders exist, save_path should be empty):
    <pre>data_path = './../Data/Heart/3D/Segmented_noisy/'
    save_path = './../Data/Heart/3D/Segmented_lim_data/'</pre>
2.  As previously, to generate a hdf5 file, execute:
    <pre>python heart_augment_loader.py</pre>
    make sure that the variable 'syn_data_path' corresponds to your new folder, containing limited data:
    <pre>syn_data_path = './../Data/Heart/3D/Segmented_lim_data_more/'</pre>
## Training the network
1.  For training the network, the script main.py should be exectued.
    The Model and log directories, as well as the fold have to be provided, e.g.:
    
    <pre>python main.py --dataset=./data_processing/aug_heart_data_noisy.h5 --name=Heart_full --log_name=Heart_full --fold=4</pre>
    Make sure that the location of your dataset matches the path given with --dataset and that the directories
    'Heart_full' exist inside the folders 'Models' and 'logs' as described above.
    
    For the project, no cross-validation was done. Instead fold 4 was chosen for a simple train-val-test split.
    
## Testing the network
1.  Concrete test instructions for pre-trained model provided in next section, general case here.

2.  First, create the test dataset. This contains all volumes without flips and rotations. 
    Crops are non-random to reconstruct the whole image based on the crops. Execute:
    
    <pre>python heart_test_loader.py</pre>
3.  Afterwards, execute:
    <pre>python overall_test.py --dataset=./data_processing/aug_heart_data_test.h5 --name=Heart_full --log_name=Heart_full --mode=test</pre>
    which creates results and metrics for analysis.
    The parameters after '--name' and '--log_name' once more indicate the Directories 'Models' and 'logs'
    where the training files were deposited. 
    
    By choosing '--mode=test' you will get evaluation of the test set.
    An additional parameter '--checkpoints='latest'' may be defined if the latest checkpoint should be loaded instead of 'best_dice'
    The parameter 'gen_img' can be set to 'True' to generate images in addition to analysing metrics
4.  Plotting results can be done by navigating into:
    <pre>cd Results/Plotting</pre>
    and executing:
    <pre>python metric_plots.py</pre>
    
## Testing with pretrained Network
1.  (Same as above) First, create the test dataset. This contains all volumes without flips and rotations. 
    Crops are non-random to reconstruct the whole image based on the crops. Execute:
    
    <pre>python heart_test_loader.py</pre>
    
2.  Inside the file overall_test.py, change the parameter 'save_path' to the setup, e.g.:
    <pre>save_path = './Results/Heart_full'
    save_path = './Results/Heart_limited'</pre>
    and make sure these directories exist inside the 'Results folder'.
    
3.  Testing the model with full data, 3 cases present to generate evaluations for all sets (training, validation, test)
    Choose which of the 3 commands to execute:
    
    <pre>python overall_test.py --dataset=./data_processing/aug_heart_data_test.h5 --name=Heart_full --log_name=Heart_full --mode=test
    python overall_test.py --dataset=./data_processing/aug_heart_data_test.h5 --name=Heart_full --log_name=Heart_full --mode=validation
    python overall_test.py --dataset=./data_processing/aug_heart_data_test.h5 --name=Heart_full --log_name=Heart_full --mode=train</pre>
    
4.  Testing the model with limited data (use latest checkpoint, as during training the dice is not accurate due to having unpaired images)
    Choose which of the 3 commands to execute:

    <pre>python overall_test.py --dataset=./data_processing/aug_heart_data_test.h5 --name=Heart_limited --log_name=Heart_limited --mode=test --checkpoint=latest
    python overall_test.py --dataset=./data_processing/aug_heart_data_test.h5 --name=Heart_limited --log_name=Heart_limited --mode=validation --checkpoint=latest
    python overall_test.py --dataset=./data_processing/aug_heart_data_test.h5 --name=Heart_limited --log_name=Heart_limited --mode=train --checkpoint=latest</pre>
    
5.  Once more, plotting results can be done by navigating into:
    <pre>cd Results/Plotting</pre>
    and executing:
    <pre>python metric_plots.py</pre>
    The parameters 'mode' and 'evaldir' inside the script should be modified to the desired split and Results directory, e.g. 
    <pre>mode = 'test'
    evaldir = './../Heart_full'</pre>
### Parameters

All parameters are of the shape: --&lt;parameter_name&gt;=&lt;value&gt; <br />
Below is the list of all possible parameters that can be set. The standard value used if the parameter is not defined is given in brackets

<b>name ('unnamed')</b><br />
Name of the model. This value should be unique to not load/overwrite old models. Its value must be changed to ensure functionality!
<br />

<b>logs_name ('logs')</b><br />
Name of the model. This value should be unique to not load/overwrite old models. Its value must be changed to ensure functionality!
<br />

<b>dataset ('pathtodata.h5')</b><br />
Describes which h5 files is used. Its value must be changed to ensure functionality!
<br />

<b>architecture ('Res6')</b><br />
The network architecture for the generators. Currently, you can choose between 'Res6' and 'Res9', which corresponds to 6 and 9 residual layers, respectively.
<br />

<b>deconv ('transpose')</b><br />
Upsampling method used in the generators. You can either choose transpose CNNs ('transpose') or image resizing ('resize').
<br />

<b>PatchGAN ('Patch70')</b><br />
Different PatchGAN Architectures: 'Patch34', 'Patch70', or 'Patch142'. A mixture of these is possible: 'MultiPatch' (experimental).
<br />


<b>dataset ('pathtodata.h5')</b><br />
Describes which h5 files is used. Its value must be changed to ensure functionality!
<br />

<b>lambda_c (10.)</b><br />
The loss multiplier of the cycle consistency term used while training the generators.
<br />

<b>lambda_h (1.)</b><br />
The loss multiplier of the histogram discriminators. If the histogram should not be used, set this term to 0.
<br />

<b>dis_noise (0.1)</b><br />
To make the network more stable, we added noise to the input of the discriminators, which slowly decays over time. This value describes how high the std of the gaussian noise is, which is added to the inputs.
<br />

<b>syn_noise (0.)</b><br />
It is possible to add gaussian noise to the synthetic dataset. Default: not used.
<br />

<b>real_noise (0.)</b><br />
It is possible to add gaussian noise to the real dataset. Default: not used.
<br />

<b>epoch (200)</b><br />
Number of training epochs.
<br />

<b>batch_size (2)</b><br />
Batch size during training.
<br />

<b>buffer_size (50)</b><br />
Size of the buffer (history) saved to train the discriminators. This makes the network more stable.
<br />

<b>save (1)</b><br />
If value is not 0, the network progress is saved at the end of each epoch.
<br />

<b>gpu (0)</b><br />
If multiple GPUs exist, this parameter choses which GPU should be used. Only one GPU can currently be used.
<br />

<b>verbose (0)</b><br />
If value is not 0, the network is more verbose.
<br />

<b>fold (1)</b><br />
Fold of network. For project, fold 4 is used due to time constraints.
<br />
