# Cycle-GAN / UDCT
Modified version of the UDCT cycle-GAN. Uses a different data processing pipeline compared to the original and includes proper validation / test phase.

This version uses Tensorflow(-GPU) 1.4 and Python 2.7 (chosen for original implementation)

Tests with python 3.6 and TF-GPU 1.5 were also done and the code seemed to work (in depth-testing still required, 
currently not advised to use this configuration since requirements are given for
Python 2.7 and TF 1.4)
Other requirements are provided in the file requirements.txt.

Note: The code was executed on a cluster via an interactive terminal shell in the code directory. 
All paths are relative. If submission of a batch file is desired, some paths might have to be set to absolute ones.

A short description of the most relevant scripts is provided at the bottom of the README.

Due to limited space for storing large files on github, only one pretrained model has been uploaded (full data model).
Additional pre-trained networks can be requested by writing an email to: 
[cenerd@student.ethz.ch](mailto:cenerd@student.ethz.ch)
## Installation
1.  Clone or download the repository:
    <pre> git clone https://github.com/Demisio/UDCT.git </pre>
2.  Create an environment for the packages to be installed. With conda, e.g (less tested with python 3.6 & TF 1.5 but seems to work): 
    <pre >conda create -n UDCT python=2.7 
    conda create -n UDCT python=3.6</pre>

2.  Install requirements (include TF 1.4, some packages might not be compatible with python 3, 
    need to manually remove these packages if python 3 is absolutely desired) via: 
    <pre> pip install -r requirements.txt </pre>
4.  Required CUDA / CUDNN versions:
    <pre>Python 2.7, TF 1.4: CUDA 8.0 / CUDNN 6.0
    Python 3.6, TF 1.5: CUDA 9.0 / CUDNN 7.0</pre>
    
## Creating a Dataset, Data Splits and Log Folders
1.  Images are given in ./Data/Heart/3D. Creating a hdf5 dataset is achieved by navigating into the folder dataprocessing
    and executing the file heart_augment_loader.py 
    (make sure that variables raw_data_path & syn_data_path inside the file are defined as shown below):
    
    <pre>raw_data_path = './../Data/Heart/3D/Raw/'
    syn_data_path = './../Data/Heart/3D/Segmented_noisy/'
    
    cd data_processing
    python heart_augment_loader.py</pre>
2.  Datasplits are already provided but can be generated by navigating into the folder ./train_test_split and executing
    the file create_splits.py
    <pre>cd train_test_split
    python create_splits.py</pre>
3.  2 Dictionaries, called "logs" and "Models" have to be created in the main Project folder. These dictionaries should
    contain subfolders with the name of the experiment and 5 subsubfolders called fold_1 until fold_5, e.g.:
    <pre>./Models/Heart_full/fold_3
    ./logs/Heart_full/fold_3</pre>
   
    For the project, fold 3 was chosen and treated as a standard train / val / test split.
   
## Creating a Dataset with Limited Data (skip if full data desired)
1.  (All limited volumes already provided, step included for completion. Directly skip to step 2)

    Navigate into the folder 'data_processing' and execute:
    <pre>cd data_processing
    python heart_lim_dat_from_full_dat.py</pre>
    This creates new volumes with the same size as the others but containing limited and duplicated data.
    
    The variable data_path and save_path inside the script define which data should be used and where it should be saved respectively.
    values could be as shown below (make sure folders exist, save_path should be empty):
    <pre>data_path = './../Data/Heart/3D/Segmented_noisy/'
    save_path = './../Data/Heart/3D/Segmented_very_lim_data/'</pre>
    
2.  As previously, make sure that the variables 'raw_data_path' & 'syn_data_path' correspond to your new folders, containing limited data:
    Then generate a hdf5 file by executing:
    <pre>raw_data_path = './../Data/Heart/3D/Raw/'
    syn_data_path = './../Data/Heart/3D/Segmented_very_lim_data/'
    
    python heart_augment_loader.py</pre>

## Training the network
1.  For training the network, the script main.py should be exectued.
    The Model and log directories, as well as the fold have to be provided, e.g.:
    
    <pre>python main.py --dataset=./data_processing/aug_heart_data_noisy.h5 --name=Heart_full --log_name=Heart_full --fold=3</pre>
    Make sure that the location of your dataset matches the path given with --dataset and that the directories
    'Heart_full' exist inside the folders 'Models' and 'logs' as described above.
    
    For the project, no cross-validation was done. Instead fold 3 was chosen for a simple train-val-test split.
    
## Testing the network
1.  Concrete test instructions for pre-trained model provided in next section, general case here.

2.  First, create the test dataset. This contains all volumes without flips and rotations. 
    Crops are non-random to reconstruct the whole image based on the crops. Execute:
    
    <pre>python heart_test_loader.py</pre>
    
3.  Open the file 'overall_test.py' and make sure you set the variable 'save_path' according to your model
    configuration. If you model name is 'Heart_full', make sure this subfolder exists in './Results'
    and set the value of 'save_path' as follows:
    <pre>save_path = './Results/Heart_full'</pre>
    
3.  Afterwards, execute:
    <pre>python overall_test.py --dataset=./data_processing/aug_heart_data_test.h5 --name=Heart_full --log_name=Heart_full --mode=test</pre>
    which creates results and metrics for analysis.
    The parameters after '--name' and '--log_name' once more indicate the Directories 'Models' and 'logs'
    where the training files were deposited. 
    
    By choosing '--mode=test' you will get evaluation of the test set.
    An additional parameter '--checkpoints='latest'' may be defined if the latest checkpoint should be loaded instead of 'best_dice'
    The parameter 'gen_img' (in the script overall_test.py) can be set to 'True' to generate images in addition to analysing metrics
    
4.  Plotting results (collagen fraction plots, other plots are in Unet Code directory) can be done by navigating into:
    <pre>cd Results/Plotting</pre>
    and executing:
    <pre>python metric_plots.py</pre>
    
## Testing with pretrained Network
1.  (Same as above) First, create the test dataset. This contains all volumes without flips and rotations. 
    Crops are non-random to reconstruct the whole image based on the crops. Execute:
    
    <pre>python heart_test_loader.py</pre>
    
2.  Inside the file overall_test.py, change the parameter 'save_path' to the setup, e.g.:
    <pre>save_path = './Results/Heart_full'
    save_path = './Results/Heart_limited'</pre>
    and make sure these directories exist inside the 'Results' folder.
    
3.  Testing the model with full data, 3 cases present to generate evaluations for all sets (training, validation, test)
    Choose which of the 3 commands to execute (for test set results, choose first case):
    
    <pre>python overall_test.py --dataset=./data_processing/aug_heart_data_test.h5 --name=Heart_full --log_name=Heart_full --mode=test
    python overall_test.py --dataset=./data_processing/aug_heart_data_test.h5 --name=Heart_full --log_name=Heart_full --mode=validation
    python overall_test.py --dataset=./data_processing/aug_heart_data_test.h5 --name=Heart_full --log_name=Heart_full --mode=train</pre>
    
4.  Testing the model with limited data (use latest checkpoint, as during training the dice is not accurate due to having unpaired images)
    Choose which of the 3 commands to execute (for test set results, choose first case):

    <pre>python overall_test.py --dataset=./data_processing/aug_heart_data_test.h5 --name=Heart_limited --log_name=Heart_limited --mode=test --checkpoint=latest
    python overall_test.py --dataset=./data_processing/aug_heart_data_test.h5 --name=Heart_limited --log_name=Heart_limited --mode=validation --checkpoint=latest
    python overall_test.py --dataset=./data_processing/aug_heart_data_test.h5 --name=Heart_limited --log_name=Heart_limited --mode=train --checkpoint=latest</pre>
    
5.  Once more, plotting results can be done by navigating into:
    <pre>cd Results/Plotting</pre>
    and executing:
    <pre>python metric_plots.py</pre>
    The parameters 'mode' and 'evaldir' inside the script should be modified to the desired split and Results directory, e.g. 
    <pre>mode = 'test'
    evaldir = './../Heart_full'</pre>
    
### Creating the GAN-augmented dataset:
1.  First, the network has to be trained with limited data (as explained above)

2.  Create a hdf5 file with 'heart_augment_loader.py', specify parameters as follows:
    <pre>filename = 'gan_data.h5'
    raw_data_path = './../Data/Heart/3D/Raw_very_lim_data/'
    syn_data_path = './../Data/Heart/3D/Segmented_og_labels_very_lim/'
    
    #execute
    python heart_augment_loader.py</pre>
    
3.  When running the file 'overall_test.py', make sure the variable 'gen_img' is set to 'True':
    <pre>gen_img = True</pre>
 
4.  Execute:
    <pre>python data_processing/combine_data_gan_normal.py</pre>
    
    This modifies the previously created hdf5 file with the newly created GAN data (Training set).
    
5.  Copy this newly modified hdf5 file 'gan_data.h5' into the folder 'data_processing' of the Unet Directory.
    This will allow testing the Unet with UDCT-augmented data.
### Relevant Files

<b>cycleGAN.py</b><br />
Contains the overall model flow and pipeline, interacts with most of the other files presented here
<br />

<b>main.py</b><br />
Execute for training the model, contains several parameters
<br />

<b>overall_test.py</b><br />
Test a trained model, create pickle dictionaries containing results
<br />

<b>data_processing/heart_augment_loader.py</b><br />
Creates hdf5 data based on the volumes, necessary for running the model
<br />

<b>data_processing/heart_test_loader.py</b><br />
Creates test set hdf5 data (non-augmented, symmetric crops)
<br />

<b>data_processing/batch_provider.py</b><br />
Batch provider to get pseudo-random sampling of batches while trying to avoid repetition as much as possible
<br />

<b>data_processing/heart_data.py</b><br />
Provides the heart data with the given data split, interacts with the model itself and the batch provider.
<br />

<b>Discriminator</b><br />
Folder contains the Discriminator architecture
<br />

<b>Generator</b><br />
Folder contains the Generator architecture
<br />

### Parameters

All parameters are of the shape: --&lt;parameter_name&gt;=&lt;value&gt; <br />
Below is the list of all possible parameters that can be set. The standard value used if the parameter is not defined is given in brackets

<b>name ('unnamed')</b><br />
Name of the model. This value should be unique to not load/overwrite old models. Its value must be changed to ensure functionality!
<br />

<b>logs_name ('logs')</b><br />
Name of the model. This value should be unique to not load/overwrite old models. Its value must be changed to ensure functionality!
<br />

<b>dataset ('pathtodata.h5')</b><br />
Describes which h5 files is used. Its value must be changed to ensure functionality!
<br />

<b>architecture ('Res6')</b><br />
The network architecture for the generators. Currently, you can choose between 'Res6' and 'Res9', which corresponds to 6 and 9 residual layers, respectively.
<br />

<b>deconv ('transpose')</b><br />
Upsampling method used in the generators. You can either choose transpose CNNs ('transpose') or image resizing ('resize').
<br />

<b>PatchGAN ('Patch70')</b><br />
Different PatchGAN Architectures: 'Patch34', 'Patch70', or 'Patch142'. A mixture of these is possible: 'MultiPatch' (experimental).
<br />


<b>dataset ('pathtodata.h5')</b><br />
Describes which h5 files is used. Its value must be changed to ensure functionality!
<br />

<b>lambda_c (10.)</b><br />
The loss multiplier of the cycle consistency term used while training the generators.
<br />

<b>lambda_h (1.)</b><br />
The loss multiplier of the histogram discriminators. If the histogram should not be used, set this term to 0.
<br />

<b>dis_noise (0.1)</b><br />
To make the network more stable, we added noise to the input of the discriminators, which slowly decays over time. This value describes how high the std of the gaussian noise is, which is added to the inputs.
<br />

<b>syn_noise (0.)</b><br />
It is possible to add gaussian noise to the synthetic dataset. Default: not used.
<br />

<b>real_noise (0.)</b><br />
It is possible to add gaussian noise to the real dataset. Default: not used.
<br />

<b>epoch (200)</b><br />
Number of training epochs.
<br />

<b>batch_size (2)</b><br />
Batch size during training.
<br />

<b>buffer_size (50)</b><br />
Size of the buffer (history) saved to train the discriminators. This makes the network more stable.
<br />

<b>save (1)</b><br />
If value is not 0, the network progress is saved at the end of each epoch.
<br />

<b>gpu (0)</b><br />
If multiple GPUs exist, this parameter choses which GPU should be used. Only one GPU can currently be used.
<br />

<b>verbose (0)</b><br />
If value is not 0, the network is more verbose.
<br />

<b>fold (1)</b><br />
Fold of network. For project, fold 4 is used due to time constraints.
<br />
